{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cafd1228-ebb5-4479-80c3-dbb8b149f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bcd2d6-894c-47f3-9099-b34a124fca14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset: \n",
      "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
      "0  LP001002   Male      No          0      Graduate            No   \n",
      "1  LP001003   Male     Yes          1      Graduate            No   \n",
      "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
      "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
      "4  LP001008   Male      No          0      Graduate            No   \n",
      "\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             5849                0.0         NaN             360.0   \n",
      "1             4583             1508.0       128.0             360.0   \n",
      "2             3000                0.0        66.0             360.0   \n",
      "3             2583             2358.0       120.0             360.0   \n",
      "4             6000                0.0       141.0             360.0   \n",
      "\n",
      "   Credit_History Property_Area Loan_Status  \n",
      "0             1.0         Urban           Y  \n",
      "1             1.0         Rural           N  \n",
      "2             1.0         Urban           Y  \n",
      "3             1.0         Urban           Y  \n",
      "4             1.0         Urban           Y  \n",
      "Test Dataset: \n",
      "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
      "0  LP001015   Male     Yes          0      Graduate            No   \n",
      "1  LP001022   Male     Yes          1      Graduate            No   \n",
      "2  LP001031   Male     Yes          2      Graduate            No   \n",
      "3  LP001035   Male     Yes          2      Graduate            No   \n",
      "4  LP001051   Male      No          0  Not Graduate            No   \n",
      "\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             5720                  0       110.0             360.0   \n",
      "1             3076               1500       126.0             360.0   \n",
      "2             5000               1800       208.0             360.0   \n",
      "3             2340               2546       100.0             360.0   \n",
      "4             3276                  0        78.0             360.0   \n",
      "\n",
      "   Credit_History Property_Area  \n",
      "0             1.0         Urban  \n",
      "1             1.0         Urban  \n",
      "2             1.0         Urban  \n",
      "3             NaN         Urban  \n",
      "4             1.0         Urban  \n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv('Training Dataset.csv')\n",
    "test_df = pd.read_csv('Test Dataset.csv')\n",
    "print(\"Training Dataset: \")\n",
    "print(train_df.head())\n",
    "print(\"Test Dataset: \")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d7bcfd-c6da-4390-bb13-143d53dc3eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def preprocess_data(train_df, test_df):\n",
    "    train_y = train_df['Loan_Status']\n",
    "    train_X = train_df.drop(['Loan_ID', 'Loan_Status'], axis=1)\n",
    "    test_X = test_df.drop(['Loan_ID'], axis=1)\n",
    "\n",
    "    # Categorical and numerical columns\n",
    "    cat_cols = train_X.select_dtypes(include=['object']).columns\n",
    "    num_cols = train_X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "    # ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', SimpleImputer(strategy='median'), num_cols),\n",
    "            ('cat', Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "            ]), cat_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fiting the preprocessor on the training data and transform both train and test data\n",
    "    train_X_preprocessed = preprocessor.fit_transform(train_X)\n",
    "    test_X_preprocessed = preprocessor.transform(test_X)\n",
    "\n",
    "    # Encoding the target variable\n",
    "    le = LabelEncoder()\n",
    "    train_y = le.fit_transform(train_y)\n",
    "\n",
    "    return train_X_preprocessed, train_y, test_X_preprocessed, preprocessor, le\n",
    "\n",
    "train_X, train_y, test_X, preprocessor, label_encoder = preprocess_data(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12517bbe-a8f4-4c7d-8607-337d4f96e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_X_scaled = scaler.fit_transform(train_X)\n",
    "test_X_scaled = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302bb145-282d-4e8c-8e00-95c8fb178ff5",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98a1dfbf-29e5-47a5-bf01-0e2e9451db05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# K-Means Clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "train_df['KMeans_Cluster'] = kmeans.fit_predict(train_X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8920910-63a0-4433-b955-029789a09f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Clustering\n",
    "hierarchical = AgglomerativeClustering(n_clusters=2)\n",
    "train_df['Hierarchical_Cluster'] = hierarchical.fit_predict(train_X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37dba974-4495-449e-ba82-1cae86d337d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "train_df['DBSCAN_Cluster'] = dbscan.fit_predict(train_X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce20680f-d347-44aa-827f-6c5b5d8136f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Mixture Models\n",
    "gmm = GaussianMixture(n_components=2, random_state=0)\n",
    "train_df['GMM_Cluster'] = gmm.fit_predict(train_X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c826e-1495-4d29-ae0c-37ab135987cb",
   "metadata": {},
   "source": [
    "#### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bd5c32d-65c5-49b6-8b8a-3833bc90259c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.998371335504886\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "bagging = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=0)\n",
    "bagging.fit(train_X_scaled, train_y)\n",
    "y_pred_bagging = bagging.predict(test_X_scaled)\n",
    "print(\"Bagging Accuracy:\", accuracy_score(train_y, bagging.predict(train_X_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88bd6298-eae9-4cd6-b793-d57f480bfd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosting Accuracy: 0.8387622149837134\n"
     ]
    }
   ],
   "source": [
    "# Boosting\n",
    "boosting = GradientBoostingClassifier(n_estimators=50, random_state=0)\n",
    "boosting.fit(train_X_scaled, train_y)\n",
    "y_pred_boosting = boosting.predict(test_X_scaled)\n",
    "print(\"Boosting Accuracy:\", accuracy_score(train_y, boosting.predict(train_X_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cf9c5c9-0ed9-4b4b-b074-b7b1e3c1ffcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Accuracy: 0.9022801302931596\n"
     ]
    }
   ],
   "source": [
    "# Stacking\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=10, random_state=0)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=10, random_state=0))\n",
    "]\n",
    "stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stacking.fit(train_X_scaled, train_y)\n",
    "y_pred_stacking = stacking.predict(test_X_scaled)\n",
    "print(\"Stacking Accuracy:\", accuracy_score(train_y, stacking.predict(train_X_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23db06bc-5688-428c-aa1b-1e4ae970fa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf.fit(train_X_scaled, train_y)\n",
    "y_pred_rf = rf.predict(test_X_scaled)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(train_y, rf.predict(train_X_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a5a93a0-8bd7-4c94-9c9f-397fe34cd533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.8729641693811075\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gb.fit(train_X_scaled, train_y)\n",
    "y_pred_gb = gb.predict(test_X_scaled)\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(train_y, gb.predict(train_X_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2e0c9a-55f3-4f80-9e54-c8bb2a50bf9d",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eda663e0-bb69-4d44-bed0-ab6336e377be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Accuracy: 0.8127035830618893\n"
     ]
    }
   ],
   "source": [
    "# L1 Regularization (Lasso)\n",
    "lasso = LogisticRegression(penalty='l1', solver='saga', max_iter=5000)\n",
    "lasso.fit(train_X_scaled, train_y)\n",
    "y_pred_lasso = lasso.predict(test_X_scaled)\n",
    "print(\"Lasso Accuracy:\", accuracy_score(train_y, lasso.predict(train_X_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b449bfe3-3852-44e3-89a1-79d77eb2ca14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Accuracy: 0.8127035830618893\n"
     ]
    }
   ],
   "source": [
    "# L2 Regularization (Ridge)\n",
    "ridge = LogisticRegression(penalty='l2', solver='saga', max_iter=5000)\n",
    "ridge.fit(train_X_scaled, train_y)\n",
    "y_pred_ridge = ridge.predict(test_X_scaled)\n",
    "print(\"Ridge Accuracy:\", accuracy_score(train_y, ridge.predict(train_X_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2645adc-b3f3-4243-aa99-196c0138b86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Accuracy: 0.8127035830618893\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet Regularization\n",
    "elasticnet = LogisticRegression(penalty='elasticnet', l1_ratio=0.5, solver='saga', max_iter=5000)\n",
    "elasticnet.fit(train_X_scaled, train_y)\n",
    "y_pred_elasticnet = elasticnet.predict(test_X_scaled)\n",
    "print(\"ElasticNet Accuracy:\", accuracy_score(train_y, elasticnet.predict(train_X_scaled)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
